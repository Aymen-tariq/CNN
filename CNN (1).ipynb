{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy4s1c-cfyiA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from tensorflow.keras.datasets.cifar10 import load_data\n",
        " \n",
        " \n",
        "(X_train, y_train), (X_test, y_test) = load_data()\n",
        " \n",
        "# rescale image\n",
        "X_train_scaled = X_train / 255.0\n",
        "X_test_scaled = X_test / 255.0\n",
        " \n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), input_shape=(32, 32, 3), padding=\"same\", activation=\"relu\", kernel_constraint=MaxNorm(3)),\n",
        "    Dropout(0.3),\n",
        "    Conv2D(32, (3,3), padding=\"same\", activation=\"relu\", kernel_constraint=MaxNorm(3)),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation=\"relu\", kernel_constraint=MaxNorm(3)),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation=\"sigmoid\")\n",
        "])\n",
        " \n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\", \n",
        "              metrics=\"sparse_categorical_accuracy\")\n",
        " \n",
        "model.fit(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test), epochs=25, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Km7ZGXF_fzmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layers[0].kernel)"
      ],
      "metadata": {
        "id": "X-PBQQIlf2os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract output from each layer\n",
        "extractor = tf.keras.Model(inputs=model.inputs,\n",
        "                           outputs=[layer.output for layer in model.layers])\n",
        "features = extractor(np.expand_dims(X_train[7], 0))\n",
        " \n",
        "# Show the 32 feature maps from the first layer\n",
        "l0_features = features[0].numpy()[0]\n",
        " \n",
        "fig, ax = plt.subplots(4, 8, sharex=True, sharey=True, figsize=(16,8))\n",
        "for i in range(0, 32):\n",
        "    row, col = i//8, i%8\n",
        "    ax[row][col].imshow(l0_features[..., i])\n",
        " \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R31vRgHSf9wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the 32 feature maps from the third layer\n",
        "l2_features = features[2].numpy()[0]\n",
        " \n",
        "fig, ax = plt.subplots(4, 8, sharex=True, sharey=True, figsize=(16,8))\n",
        "for i in range(0, 32):\n",
        "    row, col = i//8, i%8\n",
        "    ax[row][col].imshow(l2_features[..., i])\n",
        " \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J5Sg9R9OgABt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}